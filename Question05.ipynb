{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-14T03:35:17.294477Z",
     "start_time": "2026-02-14T03:35:17.252994Z"
    }
   },
   "source": [
    "#TRAIN/TEST SPLIT FROM QUESTION 4\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer #Added so we can deal with NaN values\n",
    "\n",
    "kidney_disease_data_frame = pd.read_csv(\"D:/datasets/kidney_disease.csv\")\n",
    "\n",
    "#EXTRA EDIT: Removing id column because it does not have data, just id numbers\n",
    "kidney_disease_data_frame = kidney_disease_data_frame.drop(columns=['id'], errors='ignore')\n",
    "kidney_disease_data_frame['classification'] = kidney_disease_data_frame['classification'].str.strip()\n",
    "\n",
    "\n",
    "#Including all columns except the last.\n",
    "feature_matrix = kidney_disease_data_frame.drop(columns=['classification'])\n",
    "\n",
    "#EXTRA EDIT: Changing strings into number so KNN model can use all the data\n",
    "feature_matrix = pd.get_dummies(feature_matrix, drop_first=True)\n",
    "\n",
    "#Making labels = last column\n",
    "target_labels = kidney_disease_data_frame['classification']\n",
    "\n",
    "\n",
    "model_features_train, model_features_test, model_labels_train, model_labels_test = train_test_split(feature_matrix, target_labels, test_size= 0.3, random_state=69)\n",
    "\n",
    "#EXTRA EDIT: Replacing null values with median of column to retain as much data as possible instead of dropping row.\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "model_features_train = imputer.fit_transform(model_features_train)\n",
    "model_features_test = imputer.transform(model_features_test)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T03:35:19.794963Z",
     "start_time": "2026-02-14T03:35:19.725837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#FINDING ACCURACY FOR DIFFERENT K VALUES\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "possible_k_values = [1, 3, 5, 7, 9]\n",
    "\n",
    "for i in possible_k_values:\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_model.fit(model_features_train, model_labels_train) #Model Training\n",
    "\n",
    "    predicted_labels = knn_model.predict(model_features_test) #Getting estimated values from test set\n",
    "\n",
    "    accuracy = accuracy_score(model_labels_test, predicted_labels) #Calculated accuracy score for each k\n",
    "    accuracy_list.append(accuracy)\n",
    "\n"
   ],
   "id": "75e019fb934d2db",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-14T03:35:21.814739Z",
     "start_time": "2026-02-14T03:35:21.804485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#CREATING A TABLE FROM ACCURACY LIST\n",
    "\n",
    "results_table = pd.DataFrame({\n",
    "    'K-Value': possible_k_values,\n",
    "    'Accuracy': accuracy_list\n",
    "})\n",
    "\n",
    "print(results_table)"
   ],
   "id": "ad2476b859c9d590",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   K-Value  Accuracy\n",
      "0        1  0.808333\n",
      "1        3  0.808333\n",
      "2        5  0.783333\n",
      "3        7  0.808333\n",
      "4        9  0.800000\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#How changing k affects the behavior of the model\n",
    "#Changing k changes the behavior of the model because \"k\" is the number of neighbors, or the mathematically closest data points to the given data point to make a prediction. This ultimately can lead to overfitting or underfitting as too little or too many parameters are given.\n",
    "\n",
    "#Why very small values of k may cause overfitting\n",
    "#Very small values of k may cause overfitting as only a small amount of other data points are taken into consideration when making a prediction, making it more sensitive to outliers as the prediction is reliant on only a few points that it memorizes.\n",
    "\n",
    "#Why very large values of k may cause underfitting\n",
    "#Very large values of k make the model oversimplify itself as it greatly broadens the number of inputs taken to predict values, this means specific data may get washed out and predictions made may just be based on what class is a majority among the neighbours. This is problematic in situations like this one where we are looking for potential kidney failure, we do not want the model to instantly claim a patient does not have kidney disease because the majority of the neighbours of the data are patients without kidney disease."
   ],
   "id": "3d18371903efd8a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
